{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from d2l import AllDeepLearning as d2l\n",
    "from d2l import d2l_mx\n",
    "from mxnet import autograd, gluon, nd\n",
    "from mxnet.gluon import nn\n",
    "from AI.AILearning.NaturalLanguageProcessing import WordEmbedding as loader\n",
    "\n",
    "import math\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'sentences: 42069'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with zipfile.ZipFile('../../data/ptb.zip', 'r') as f:\n",
    "    raw_text = f.read('ptb/ptb.train.txt').decode(\"utf-8\").lower()\n",
    "\n",
    "sentences = [line.split() for line in raw_text.split(\"\\n\")]\n",
    "'sentences: %d' % len(sentences)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'vocab size: 6719'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "def expand(sentences):\n",
    "    \"\"\"\n",
    "    Expand list of token lists into a list of tokens\n",
    "    :param sentences:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return [tk for line in sentences for tk in line]\n",
    "\n",
    "vocab = d2l_mx.Vocab(expand(sentences), min_freq=10)\n",
    "'vocab size: %d' % len(vocab)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "42069"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "# Subsampling\n",
    "# Map low frequency words into <unk>\n",
    "sentences = [[vocab.idx_to_token[vocab[tk]] for tk in line] for line in sentences]\n",
    "tokens = expand(sentences)\n",
    "counter = collections.Counter(tokens)\n",
    "\n",
    "def discard(token):\n",
    "    \"\"\"\n",
    "\n",
    "    :param token:\n",
    "    :return: should discard token when it has too high frequency\n",
    "    \"\"\"\n",
    "    p = 1 - math.sqrt(1e-4 / counter[token] * len(tokens))\n",
    "    return random.uniform(0, 1) < p\n",
    "\n",
    "subsampled = [[tk for tk in line if not discard(tk)] for line in sentences]\n",
    "subsampled.__len__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x1dfa436ec18>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist([[len(line) for line in sentences], [len(line) for line in subsampled]])\n",
    "plt.legend(['origin', 'subsampled'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'count of \"join\": before-45, after-45'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_counts(token):\n",
    "    return 'count of \"%s\": before-%d, after-%d' % (\n",
    "        token,\n",
    "        sum([line.count(token) for line in sentences],),\n",
    "        sum([line.count(token) for line in subsampled])\n",
    "    )\n",
    "\n",
    "compare_counts('join')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0, 0, 0],\n [71, 2132, 18, 275],\n [140, 5464, 3080, 1595],\n [2476, 656, 2169, 954, 38, 302, 437, 3683],\n [941,\n  3,\n  3149,\n  262,\n  4,\n  6091,\n  4240,\n  6035,\n  987,\n  240,\n  759,\n  1014,\n  2785,\n  95,\n  430,\n  4114,\n  4,\n  1243],\n [3149, 4051, 495, 21, 112, 2651, 2473, 5249, 3003, 465, 1243]]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map each token into index to construct corpus\n",
    "corpus = [vocab[line] for line in subsampled]\n",
    "corpus[:6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "center 0 has contexts [1]\n",
      "center 1 has contexts [0, 2]\n",
      "center 2 has contexts [1, 3]\n",
      "center 3 has contexts [1, 2, 4, 5]\n",
      "center 4 has contexts [3, 5]\n",
      "center 5 has contexts [3, 4, 6]\n",
      "center 6 has contexts [5]\n",
      "center 7 has contexts [8, 9]\n",
      "center 8 has contexts [7, 9]\n",
      "center 9 has contexts [8]\n"
     ]
    }
   ],
   "source": [
    "# extract central target words and context words\n",
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # Need at least 2 words to form a central target - context word\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, i - window_size), min(len(line), i + 1 + window_size)))\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts\n",
    "\n",
    "tiny_dataset=[list(range(7)),list(range(7,10))]\n",
    "print('dataset', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset,2)):\n",
    "    print('center', center,'has contexts', context)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'center-context pairs: 353163'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus, 5)\n",
    "'center-context pairs: %d' % len(all_centers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandomGenerator(object):\n",
    "    \"\"\"\n",
    "    Draw a random int in [0, n] according to n sampling weights\n",
    "    \"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        self.population = list(range(len(sampling_weights)))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            # cache 10000 random number\n",
    "            self.candidates = random.choices(self.population, self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]\n",
    "\n",
    "\n",
    "generator = RandomGenerator([2, 3, 4])\n",
    "generator.draw()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "counter = collections.Counter(expand(corpus))\n",
    "sampling_weights = [counter[i] ** 0.75 for i in range(len(counter))]\n",
    "\n",
    "def get_negatives(all_ctxs, sampling_weights, K):\n",
    "    all_negatives = []\n",
    "    generator = RandomGenerator(sampling_weights=sampling_weights)\n",
    "    for contexts in all_ctxs:\n",
    "        negatives = []\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # Noise word cannot be ctx words\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, sampling_weights=sampling_weights, K=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers - [[1]\n",
      " [1]]\n",
      "contexts_negative - [[2 2 3 3 3 3]\n",
      " [2 2 2 3 3 0]]\n",
      "masks - [[1 1 1 1 1 1]\n",
      " [1 1 1 1 1 0]]\n",
      "labels - [[1 1 0 0 0 0]\n",
      " [1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def batchify(data):\n",
    "    \"\"\"\n",
    "    Construct mini-batch by concatenate the ctx word and noise word of each example and add 0s for padding\n",
    "    To avoid effect of padding on the loss func, using mask variable with same shape and has value 0 if position is\n",
    "    padding otherwise is 1\n",
    "    To know which is the positive and negative samples, using labels variable similar to masks variable\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return np.array(centers).reshape((-1, 1)), np.array(contexts_negatives), np.array(masks), np.array(labels)\n",
    "\n",
    "\n",
    "x_1 = (1, [2, 2], [3, 3, 3, 3])\n",
    "x_2 = (1, [2, 2, 2], [3, 3])\n",
    "batch = batchify((x_1, x_2))\n",
    "\n",
    "names = ['centers', 'contexts_negative', \"masks\", 'labels']\n",
    "for name, data in zip(names, batch):\n",
    "    print(name, '-', data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers shape = (512, 1)\n",
      "contexts_negative shape = (512, 60)\n",
      "masks shape = (512, 60)\n",
      "labels shape = (512, 60)\n"
     ]
    }
   ],
   "source": [
    "# dataset with batch size 512 contain center, context, mask and label\n",
    "batch_size = 512\n",
    "dataset = gluon.data.ArrayDataset(all_centers, all_contexts, all_negatives)\n",
    "data_iter = gluon.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, batchify_fn=batchify)\n",
    "# each loop with take a tuple of batch_size center, context, mask and label\n",
    "for batch in data_iter:\n",
    "    for name, data in zip(names, batch):\n",
    "        print(name, 'shape =', data.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter embedding0_weight (shape=(20, 4), dtype=float32)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(input_dim=20, output_dim=4)\n",
    "embed.initialize()\n",
    "embed.weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "\n[[0.01438687 0.05011239 0.00628365 0.04861524]]\n<NDArray 1x4 @cpu(0)>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the input of embedding layer is index of word, When enter index i of word\n",
    "# the embedding layer return the ith row of the weight matrix as its word vector\n",
    "embed(nd.array([1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 3, 2)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mini batch multiplication\n",
    "# a batch with shape (n, a, b) and another batch with shape (n, a, c) with n is batch_size multi\n",
    "# return batch with shape (n, a, c)\n",
    "X = nd.ones((1, 3, 5))\n",
    "Y = nd.ones((1, 5, 2))\n",
    "nd.batch_dot(X, Y).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(2, 1, 3)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in forward in skip-gram the central word has shape (batch_size, 1)\n",
    "# and the concatenate context negative words has shape (batch_size, max_len), which will\n",
    "# be transform from word indexes to word vectors by the word embedding layer\n",
    "# and the output with shape (batch_size, 1, max_len) is obtained by mini batch dot\n",
    "\n",
    "def skip_gram(center, contexts_negatives, embed_v, embed_u):\n",
    "    v = embed_v(center)\n",
    "    u = embed_u(contexts_negatives)\n",
    "    pred = nd.batch_dot(v, u.swapaxes(1, 2))\n",
    "    return pred\n",
    "\n",
    "skip_gram(nd.ones((2,1)), nd.ones((2,3)), embed, embed).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4) (2, 4) (2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "\n[0.48055774 0.3620385 ]\n<NDArray 2 @cpu(0)>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use mask to avoid padding participate in loss calculation\n",
    "# when the mask is 0 the pred value will not take affect, 1 otherwise\n",
    "loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "pred = nd.array([[.5]*4]*2)\n",
    "label = nd.array([[1, 0, 1, 0]]*2)\n",
    "mask = nd.array([[1, 1, 1, 0], [1, 1, 0, 0]])\n",
    "print(pred.shape, label.shape, mask.shape)\n",
    "loss(pred, label, mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}